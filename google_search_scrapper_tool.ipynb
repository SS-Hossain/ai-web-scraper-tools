{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Ensure required modules are installed\n",
        "def install_packages():\n",
        "    packages = [\"requests\", \"beautifulsoup4\", \"pandas\", \"google-search-results\"]\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "install_packages()\n",
        "\n",
        "from serpapi import GoogleSearch\n",
        "import pandas as pd\n",
        "\n",
        "def google_search_scraper(query, num_results=10):\n",
        "    \"\"\"\n",
        "    Fetches Google search results using SerpAPI.\n",
        "    \"\"\"\n",
        "    api_key = \"your-serpapi-key-here\"  # Replace with your actual API key\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"num\": num_results,\n",
        "        \"api_key\": api_key\n",
        "    }\n",
        "\n",
        "    search = GoogleSearch(params)\n",
        "    results = search.get_dict()\n",
        "    search_results = []\n",
        "\n",
        "    if \"organic_results\" in results:\n",
        "        for result in results[\"organic_results\"]:\n",
        "            title = result.get(\"title\", \"No Title\")\n",
        "            link = result.get(\"link\", \"No Link\")\n",
        "            snippet = result.get(\"snippet\", \"No Description\")\n",
        "            search_results.append({\"Title\": title, \"Link\": link, \"Description\": snippet})\n",
        "    else:\n",
        "        print(\"No results found.\")\n",
        "\n",
        "    return search_results\n",
        "\n",
        "def save_to_csv(results, filename=\"google_search_results.csv\"):\n",
        "    \"\"\"\n",
        "    Saves the search results to a CSV file.\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame(results)\n",
        "    df.to_csv(filename, index=False)\n",
        "    print(f\"Results saved to {filename}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    query = input(\"Enter search query: \")\n",
        "    results = google_search_scraper(query)\n",
        "    if results:\n",
        "        save_to_csv(results)\n",
        "    else:\n",
        "        print(\"No results found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRVmPXdREnVS",
        "outputId": "430b8763-9ca1-4be8-c6ec-74fdd06ec318"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter search query: Latest Tesla News\n",
            "Results saved to google_search_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yEO9sDH4KLV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
